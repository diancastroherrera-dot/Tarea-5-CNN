{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjGn50ej6VsrA/hX+Kg7ZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diancastroherrera-dot/Tarea-5-CNN/blob/main/Clasificaci%C3%B3n_de_D%C3%ADgitos_%26_Clasificaci%C3%B3n_de_Ropa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Construiremos una red neuronal convolucional un ejemplo de una red neuronal convolucional (CNN) para clasificar dígitos escritos a mano en el conjunto de datos MNIST, que es un problema de clasificación de imágenes."
      ],
      "metadata": {
        "id": "cXAoJQG7vkBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#carga el conjunto de datos MNIST de digitos escritos a mano\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n"
      ],
      "metadata": {
        "id": "3EW-REPiwDty"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#exploramos el dataset\n",
        "digits.keys()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkiu-K2NwDqM",
        "outputId": "26c29bce-9ec3-4bad-adbe-d76f2ec421e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nos da como resultado\n",
        "dict_keys([\n",
        "    'data', 'target', 'frame',\n",
        "    'feature_names', 'target_names', 'images',\n",
        "    'DESCR'\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "aLfhR4UowDlK",
        "outputId": "1ce6ecaa-1f06-4168-c716-6f563e79d85e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dict_keys' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2242630272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#nos da como resultado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m dict_keys([\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'feature_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'DESCR'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dict_keys' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imprime la llave DESCR  para obtener la informacion del conjunto\n",
        "print(digits.DESCR)\n"
      ],
      "metadata": {
        "id": "XYsxz1jNwDi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizacion de una imagen"
      ],
      "metadata": {
        "id": "l6sI5eTjwxU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Es necesario fijar el indice  de la imagen que vamos a visualizar\n",
        "index = 0\n"
      ],
      "metadata": {
        "id": "xr6szknmwutt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtener la imagen del digito y su etiqueta\n",
        "image = digits.images[index]\n",
        "label = digits.target[index]\n"
      ],
      "metadata": {
        "id": "FdetVWb8wup_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimimos la representacion matricial (numerica) de la imagen\n",
        "print(image)\n"
      ],
      "metadata": {
        "id": "ee5KHYURwunv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mostramos la imagen con matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(image, cmap=plt.cm.gray)\n",
        "plt.title(f'Dígito: {label}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GFmNlrJFxhWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PARA PROCESAR DATOS"
      ],
      "metadata": {
        "id": "geKFOBZTxpXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    digits.data, digits.target,\n",
        "    test_size=0.2, random_state=42\n"
      ],
      "metadata": {
        "id": "Umc3ZsIIxsj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#notemos la longitud del conjunto de entrenamiento y de test\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "id": "gij6z3KjxhTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_tensor = tf.reshape(X_train[0], shape=(8, 8))\n",
        "print(reshaped_tensor)\n"
      ],
      "metadata": {
        "id": "xbVbBTWrxhQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "pR7yo0ohqeV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aqui se escalan las imagenes para normalizar los valores de pixeles\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "j55tiofEqePv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#El StandardScaler y el MinMaxScaler son transformadores en la biblioteca scikit-learn que se utilizan para preprocesar los datos antes de alimentarlos a un modelo de aprendizaje automático"
      ],
      "metadata": {
        "id": "zxhxAXLCtCOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MinMaxScaler:\n",
        "\n",
        "El MinMaxScaler transforma las características escalándolas a un rango específico, generalmente entre 0 y 1.\n",
        "\n",
        "El MinMaxScaler es útil cuando se quiere ajustar las características dentro de un rango específico o cuando se utilizan algoritmos sensibles a la escala de las características.\n",
        "\n",
        "En resumen, el StandardScaler se utiliza para estandarizar las características a una media de 0 y varianza de 1, mientras que el MinMaxScaler se utiliza para escalar las características a un rango específico, generalmente entre 0 y 1."
      ],
      "metadata": {
        "id": "vgJ3octatImc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_tensor = tf.reshape(X_train[0], shape=(8, 8))\n",
        "# Redondeamos para tener una mejor visualizacion\n",
        "reshaped_tensor =  tf.floor(reshaped_tensor * 100) / 100\n",
        "print(reshaped_tensor)"
      ],
      "metadata": {
        "id": "E3p-kAxWqeMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redimensionar el tensor a la forma (total, 8, 8)\n",
        "X_train = tf.reshape(X_train, (X_train.shape[0], 8, 8))\n",
        "X_test = tf.reshape(X_test, (X_test.shape[0], 8, 8))"
      ],
      "metadata": {
        "id": "gl_HW-1KqeI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# Crear el modelo de CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3),\n",
        "        activation='relu',\n",
        "        input_shape=(8, 8, 1)\n",
        "    ),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "xcwMKJnYqeGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#copilamos el modelo Crear un optimizador Adam con una tasa de aprendizaje del 0.001"
      ],
      "metadata": {
        "id": "oMMSGOlltVGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tasa de aprendizaje deseada\n",
        "learning_rate = 0.001\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)"
      ],
      "metadata": {
        "id": "TAhW1AnctSB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "xI1mjPt8tR-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "uhTLu-UGtR8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.title('Función de pérdida durante el entrenamiento')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FcAqDK09tR5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "vhyqSFgzto26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "# Convert y_test back to multiclass format\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "sensitivity = recall_score(y_test_classes, y_pred_classes, average=None)"
      ],
      "metadata": {
        "id": "Sd4Hz0rEtozS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizar la matriz de confusión como una imagen de colores\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Mostrar la sensibilidad (recall) para cada clase\n",
        "print('Sensitivity (Recall) for each class:')\n",
        "for i in range(10):\n",
        "    print(f'Class {i}: {sensitivity[i]}')"
      ],
      "metadata": {
        "id": "-24Ue2mptow4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bonus (Predecir una imagen distinta al conjunto de datos)"
      ],
      "metadata": {
        "id": "R_KU3Y2yuuIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cambia por el nombre de tu archivo\n",
        "ruta = \"/content/mi_numero.png\"\n",
        "# Escala de grises (\"L\")\n",
        "img = Image.open(ruta).convert(\"L\")\n",
        "\n",
        "# mostrar la imagen\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.title(\"Imagen original\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7ERvGXSJuxRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rdedimensionar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# redimensionar a 8x8\n",
        "img_resized = img.resize((8, 8), Image.Resampling.LANCZOS)\n",
        "\n",
        "# mostrar imagen\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(img_resized, cmap=\"gray\")\n",
        "plt.title(\"Imagen redimensionada a 8x8\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# opcional, guardamos la imagen si es necesario\n",
        "img_resized.save(\"imagen_8x8.png\")\n"
      ],
      "metadata": {
        "id": "c2GqCXBNusgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Precesamiento\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# reescalar de 0-255 a 0-16 e invertir (fondo negro = 0)\n",
        "img_array = np.array(img_resized).astype(\"float32\")\n",
        "img_array = 16 - (img_array / 255 * 16)\n",
        "\n",
        "# mostrar imagen\n",
        "plt.imshow(img_array, cmap=\"gray\")\n",
        "plt.title(\"Imagen reescalada e invertida (0-16)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ij2z0xLFu63H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# normalizar\n",
        "scaler = StandardScaler()\n",
        "img_flat = img_array\n",
        "img_scaled = scaler.fit_transform(img_flat)\n",
        "\n",
        "# Dar forma (1,8,8) que es el input del modelo\n",
        "img_tensor = img_scaled.reshape(1, 8, 8)"
      ],
      "metadata": {
        "id": "3ejJ40n_u6zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluacion\n",
        "pred = model.predict(img_tensor)\n",
        "digit = np.argmax(pred)\n",
        "print(\"Predicción:\", digit)"
      ],
      "metadata": {
        "id": "Tsr9I2WNtoui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}